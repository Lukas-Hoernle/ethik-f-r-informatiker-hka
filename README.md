# Ausarbeitung zum EU AI Act

## Inhaltsverzeichnis
# 1. Einleitung

Der EU AI Act wurde erstmals 2021 als Entwurf vorgestellt und 2024 in seiner endgültigen Form verabschiedet. Ziel dieses Gesetzesrahmens ist es, eine einheitliche und sichere Grundlage für die Entwicklung und Anwendung künstlicher Intelligenz (KI) in der Europäischen Union zu schaffen. Der EU AI Act stellt sicher, dass KI-Systeme sicher, transparent und ethisch vertretbar eingesetzt werden. Diese Einführung gibt einen Überblick über die Notwendigkeit und die Ziele des EU AI Acts.

## Einführung in den EU AI Act (ca. 200 Wörter)

Der erste Entwurf des EU AI Acts wurde 2021 vorgestellt, und die endgültige Version trat 2024 in Kraft. Dieser Rechtsrahmen zielt darauf ab, einheitliche Standards für die Entwicklung und Nutzung von KI in der EU zu etablieren. Der EU AI Act soll sicherstellen, dass KI-Systeme vertrauenswürdig und menschenzentriert sind und dabei Innovationen fördern sowie grenzüberschreitende Anwendungen ermöglichen. 

Ein wesentlicher Aspekt des EU AI Acts ist die Schaffung eines gemeinsamen Marktes für KI in Europa. Durch die Harmonisierung der Regeln können Unternehmen ihre KI-Produkte und -Dienstleistungen leichter in verschiedenen Mitgliedstaaten anbieten, was die Wettbewerbsfähigkeit der EU auf dem globalen KI-Markt stärkt. Gleichzeitig sollen durch den EU AI Act Risiken minimiert und Grundrechte geschützt werden, insbesondere in Bezug auf Datenschutz, Sicherheit und die Vermeidung von Diskriminierung  .

## Notwendigkeit des EU AI Acts (ca. 200 Wörter)

Die Notwendigkeit des EU AI Acts ergibt sich aus der zunehmenden Verbreitung und Bedeutung von KI-Technologien in verschiedenen Bereichen des täglichen Lebens und der Wirtschaft. Ohne eine klare gesetzliche Regelung könnten KI-Systeme erhebliche Risiken für die Grundrechte der Bürger darstellen, insbesondere in Bezug auf Datenschutz und Sicherheit. Zudem könnten unregulierte KI-Anwendungen zu Diskriminierung und sozialer Ungerechtigkeit führen.

Ein weiteres Problem ist das Fehlen einheitlicher Regeln innerhalb der EU, was zu einem fragmentierten Rechtsrahmen und damit zu Unsicherheiten für Unternehmen führen könnte. Der EU AI Act zielt darauf ab, diese Lücken zu schließen und einen kohärenten, unionsweiten Rechtsrahmen zu schaffen. Dies ist besonders wichtig, da KI-Systeme zunehmend in sicherheitskritischen Bereichen wie dem Gesundheitswesen, der Strafverfolgung und der öffentlichen Verwaltung eingesetzt werden. Durch klare Vorgaben und Standards sollen diese Systeme sicher und vertrauenswürdig gestaltet werden .

## Ziele des EU AI Acts (ca. 200 Wörter)

Der EU AI Act verfolgt mehrere zentrale Ziele. Erstens soll er die Entwicklung und Nutzung von KI-Systemen fördern, die sicher, transparent und ethisch vertretbar sind. Dies bedeutet, dass KI-Anwendungen den Schutz der Gesundheit und Sicherheit der Nutzer gewährleisten und negative Auswirkungen auf die Gesellschaft minimieren müssen. Zweitens soll der EU AI Act dazu beitragen, dass die Grundrechte der Bürger gewahrt bleiben, insbesondere in Bezug auf Datenschutz und Nichtdiskriminierung.

Ein weiteres Ziel ist die Förderung von Innovation und Wettbewerbsfähigkeit der EU im globalen KI-Markt. Durch die Schaffung eines einheitlichen Rechtsrahmens werden Unternehmen ermutigt, in die Entwicklung und den Einsatz von KI zu investieren, was wiederum zu wirtschaftlichem Wachstum und technologischer Fortschritt führt. Schließlich soll der EU AI Act die Forschung und Entwicklung im Bereich der KI unterstützen, indem er klare Richtlinien und Standards setzt, die als Grundlage für die Schaffung neuer Technologien dienen .
# 2. Aufbau des EU AI Act

Der EU AI Act ist in verschiedene Risikokategorien unterteilt, die den Einsatz von KI-Technologien regulieren. Die Risikobewertung erfolgt auf Basis der potenziellen Auswirkungen der KI-Systeme auf die Gesellschaft. Darüber hinaus beschreibt der EU AI Act die Mechanismen zur Durchsetzung der Regelungen, einschließlich der Bildung von Ausschüssen und Aufsichtsbehörden sowie der Einführung einer Datenbank für Hochrisiko-KI Systeme.

## 2.1 Aufteilung in Risikokategorien

### 2.1.1 Unannehmbare Risiken (ca. 300 Wörter)

Der EU AI Act definiert unannehmbare Risiken als Anwendungen, die ein hohes Risiko für die Grundrechte und die Sicherheit der Bürger darstellen. Solche Anwendungen sind in der Regel verboten. Dazu gehören beispielsweise Systeme zur Verhaltensbeeinflussung, die ohne Wissen und Einwilligung der betroffenen Personen eingesetzt werden, sowie Social Scoring Systeme, die das Verhalten oder die Eigenschaften von Personen bewerten und klassifizieren. Diese verbotenen Anwendungen können zu Diskriminierung und gesellschaftlicher Ungleichheit führen. Ausnahmen sind nur unter strengen Bedingungen erlaubt, beispielsweise wenn sie im öffentlichen Interesse liegen und durch nationale Gesetze geregelt sind. 

Die strengen Vorschriften und Verbote sollen sicherstellen, dass die Grundrechte der Bürger gewahrt bleiben und missbräuchliche Anwendungen von KI verhindert werden. Dies trägt auch zur gesellschaftlichen Akzeptanz von KI bei, indem Vertrauen in die Technologie geschaffen wird.

### 2.1.2 Hohe Risiken (ca. 300 Wörter)

Hohe Risiken umfassen KI-Anwendungen, die in Bereichen wie der kritischen Infrastruktur, dem Gesundheitswesen, der Strafverfolgung und dem Bildungswesen eingesetzt werden. Diese Systeme können erhebliche Auswirkungen auf das Leben der Menschen haben und unterliegen daher strengen Anforderungen. 

Zu den Anforderungen gehören umfangreiche Risiko-Management-Maßnahmen, regelmäßige Überprüfungen der Datenqualität und die Erstellung technischer Dokumentationen. Beispielsweise müssen KI-Systeme, die in medizinischen Geräten verwendet werden, genaue und zuverlässige Ergebnisse liefern, um die Sicherheit der Patienten zu gewährleisten. Ähnliche Anforderungen gelten für KI-Systeme in Fahrzeugen, die sicherheitsrelevante Entscheidungen treffen. 

Die Implementierung dieser Maßnahmen soll sicherstellen, dass hochriskante KI-Systeme sicher und zuverlässig sind und die Gesundheit und Sicherheit der Nutzer nicht gefährden.

### 2.1.3 Begrenzte Risiken (ca. 250 Wörter)

KI-Systeme, die ein begrenztes Risiko darstellen, wie beispielsweise Chatbots und Deepfake-Technologien, unterliegen weniger strengen Vorschriften. Hauptsächlich sind Transparenzpflichten zu beachten, die darauf abzielen, die Nutzer über den KI-Einsatz zu informieren und Manipulationen zu verhindern.

So müssen beispielsweise Chatbots deutlich machen, dass es sich um automatisierte Systeme handelt, und Deepfake-Technologien müssen entsprechend gekennzeichnet werden. Diese Transparenzpflichten sollen verhindern, dass Nutzer durch die Interaktion mit KI-Systemen getäuscht oder manipuliert werden.

Obwohl diese Maßnahmen weniger streng sind als bei Hochrisiko-Systemen, sind sie dennoch wichtig, um das Vertrauen der Nutzer zu stärken und mögliche negative Auswirkungen zu minimieren.

### 2.1.4 Geringe Risiken (ca. 250 Wörter)

Geringe Risiken umfassen KI-Systeme, die keine oder nur geringe Auswirkungen auf die Gesellschaft haben, wie etwa Spamfilter oder personalisierte Werbung. Für diese Anwendungen sind keine speziellen Regeln im EU AI Act festgelegt, was den Entwicklern größere Freiheiten lässt.

Dennoch ist es wichtig, die potenziellen Gefahren solcher Systeme zu beachten. Obwohl sie keine unmittelbaren Risiken für die Gesundheit oder Sicherheit darstellen, können sie dennoch Auswirkungen auf die Privatsphäre und das Wohlbefinden der Nutzer haben. Daher ist es wichtig, dass Entwickler auch bei diesen Anwendungen verantwortungsvoll handeln.

### 2.1.5 Allzweck KIs (General Purpose AI) (ca. 250 Wörter)

Allzweck-KI-Systeme, die in einer Vielzahl von Anwendungen eingesetzt werden können, unterliegen speziellen Anforderungen. Diese Systeme verfügen über breites Allgemeinwissen und sind vielseitig einsetzbar, was sie besonders komplex und potenziell riskant macht.

Die Anforderungen umfassen die Bereitstellung technischer Dokumentationen und die Sicherstellung, dass diese Systeme sicher und zuverlässig funktionieren. Beispiele für Allzweck-KIs sind große Sprachmodelle wie GPT-4, die in verschiedenen Bereichen eingesetzt werden können, von der Textgenerierung bis hin zur Analyse großer Datenmengen.

Die Regulierung dieser Systeme ist eine Herausforderung, da sie in vielen verschiedenen Kontexten eingesetzt werden können und daher eine flexible und umfassende Überwachung erfordern.

## 2.2 Durchsetzen der Regelungen

### 2.2.1 Bildung von Ausschüssen und Aufsichtsbehörden (ca. 300 Wörter)

Zur Durchsetzung der Regelungen im EU AI Act wurden verschiedene Ausschüsse und Aufsichtsbehörden eingerichtet. Der Europäische Ausschuss für Künstliche Intelligenz (ECAI) und nationale Aufsichtsbehörden sind für die Überwachung und Durchsetzung der Vorschriften verantwortlich.

Diese Behörden haben das Recht, auf die Dokumentationen und Daten der KI-Anbieter zuzugreifen und deren Einhaltung der Vorschriften zu überprüfen. Bei Verstößen können sie Korrekturmaßnahmen anordnen und Strafen verhängen. Die Effizienz dieser Strukturen wird kontinuierlich evaluiert, um sicherzustellen, dass die Regelungen effektiv durchgesetzt werden.

Ein zentrales Ziel dieser Strukturen ist es, sicherzustellen, dass KI-Systeme sicher und vertrauenswürdig sind und dass Verstöße schnell und wirksam geahndet werden können.

### 2.2.2 Einführung einer Datenbank für Hochrisiko-KI Systeme (ca. 250 Wörter)

Eine weitere wichtige Maßnahme zur Durchsetzung der Regelungen ist die Einführung einer Datenbank für Hochrisiko-KI Systeme. Alle Hochrisiko-KI Systeme müssen vor ihrer Inbetriebnahme in dieser Datenbank registriert werden. 

Die Datenbank ermöglicht einen Überblick über alle betriebene Hochrisiko-KI Systeme und deren Einsatzgebiete. Dies erhöht die Transparenz und Nachvollziehbarkeit der eingesetzten KI-Systeme und erleichtert die Überwachung durch die zuständigen Behörden.

Diese Maßnahme trägt dazu bei, das Vertrauen in KI-Systeme zu stärken, indem sie sicherstellt, dass alle hochriskanten Anwendungen angemessen überwacht und reguliert werden.


3. Bidens Executive Order
   - 3.1 Einführung und Ziele der Executive Order
   - 3.2 Verpflichtungen für Entwickler
   - 3.3 Weitere Ziele und Maßnahmen
4. Vergleich EU AI Act und Executive Order
   - 4.1 Unterschiede in der Risikobewertung
   - 4.2 Unterschiede in der Konkretheit der Regelungen
   - 4.3 Gemeinsame Ziele und unterschiedliche Schwerpunkte
5. Kritik am EU AI Act
   - 5.1 Ausnehmen von militärischen Systemen
     - 5.1.1 Problematik und Begründung
   - 5.2 Alignment Problem
     - 5.2.1 Herausforderung und Lösungsansätze
6. Fazit
   - 6.1 Zusammenfassung der Hauptpunkte
   - 6.2 Ausblick und zukünftige Entwicklungen

## 1. Einleitung
- **Einführung in den EU AI Act** (ca. 200 Wörter)
  - Erster Entwurf 2021, endgültige Version 2024.
  - Ziel: Rechtsrahmen für vertrauenswürdige KI schaffen.
  - Schaffung eines einheitlichen Marktes für KI in Europa.
  - Förderung von Innovationen und grenzüberschreitender Nutzung von KI.
  - Quellen: Offizielle Veröffentlichungen der EU-Kommission.

- **Notwendigkeit des EU AI Acts** (ca. 200 Wörter)
  - Steigende Risiken für Grundrechte.
  - Fehlende Ressourcen und Erlaubnisse für Überwachung.
  - Gefahr eines uneinheitlichen Rechtsrahmens innerhalb der EU.
  - Zunehmende Integration von KI in verschiedenen Sektoren.
  - Quellen: Fachliteratur zur KI-Ethik.

- **Ziele des EU AI Acts** (ca. 200 Wörter)
  - Förderung von vertrauenswürdiger und menschenzentrierter KI.
  - Schutz von Gesundheit und Sicherheit.
  - Unterbindung schädlicher Auswirkungen von KI-Systemen.
  - Unterstützung von Forschung und Entwicklung in der KI.
  - Quellen: Offizielle Veröffentlichungen der EU-Kommission.

## 2. Aufbau des EU AI Act
### 2.1 Aufteilung in Risikokategorien
#### 2.1.1 Unannehmbare Risiken (ca. 300 Wörter)
- **Verbotene Anwendungen und Ausnahmen**
  - Verbotene Anwendungen wie Verhaltensbeeinflussung und Social Scoring.
  - Risiken und ethische Bedenken bei biometrischer Identifizierung.
  - Strenge Bedingungen für Ausnahmen.
  - Auswirkungen auf die gesellschaftliche Akzeptanz.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.1.2 Hohe Risiken (ca. 300 Wörter)
- **Anwendungsbereiche und Anforderungen**
  - KIs in Schutzsystemen, Spielzeug, Medizinprodukten und kritischer Infrastruktur.
  - Anforderungen an Risiko-Management, Datenüberprüfung und technische Dokumentation.
  - Beispielhafte Fälle und deren Regulierungen.
  - Evaluierung der Wirksamkeit der Maßnahmen.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.1.3 Begrenzte Risiken (ca. 250 Wörter)
- **Transparenzpflicht und Manipulation**
  - Erhöhtes Risiko für Manipulation, z.B. bei Chatbots und Deepfakes.
  - Transparenzpflicht bei KI-generierten Inhalten.
  - Schutzmaßnahmen und deren Implementierung.
  - Diskussion über die Effektivität dieser Maßnahmen.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.1.4 Geringe Risiken (ca. 250 Wörter)
- **Anwendungsbeispiele und Freiheiten**
  - KIs wie Spamfilter oder Videospiele.
  - Keine speziellen Regeln durch den EU AI Act.
  - Vorteile und mögliche Gefahren.
  - Einfluss auf die Innovationsfreiheit.
  - Quellen: EU AI Act Dokumentation.

#### 2.1.5 Allzweck KIs (General Purpose AI) (ca. 250 Wörter)
- **Charakteristika und Anforderungen**
  - Breites Allgemeinwissen, vielfältige Einsatzmöglichkeiten.
  - Technische Dokumentation und Informationsbereitstellung erforderlich.
  - Beispiele und deren Relevanz.
  - Herausforderungen bei der Regulierung.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

### 2.2 Durchsetzen der Regelungen
#### 2.2.1 Bildung von Ausschüssen und Aufsichtsbehörden (ca. 300 Wörter)
- **Strukturen und Aufgaben**
  - Europäischer Ausschuss für KI und nationale Aufsichtsbehörden.
  - Zugriff auf Dokumentationen und Daten der KI-Anbieter.
  - Korrekturmaßnahmen und Strafen bei Nichteinhaltung.
  - Effizienz und Kritik an den Strukturen.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.2.2 Einführung einer Datenbank für Hochrisiko-KI Systeme (ca. 250 Wörter)
- **Zweck und Nutzung**
  - Registrierung vor Inbetriebnahme erforderlich.
  - Überblick über betriebene Hochrisiko-KI Systeme.
  - Transparenz und Nachvollziehbarkeit.
  - Bewertung der Praktikabilität.
  - Quellen: EU AI Act Dokumentation.

## 3. Bidens Executive Order
### 3.1 Einführung und Ziele der Executive Order (ca. 300 Wörter)
- **Hintergrund und Intention**
  - Erlassen am 30. Oktober 2023.
  - Standards für sichere, privatsphäreschützende und gleichbehandelnde KI-Systeme.
  - Förderung eines ethischen Rahmens für KI.
  - Vergleich zu früheren US-Initiativen.
  - Quellen: Analysen zur US Executive Order.

### 3.2 Verpflichtungen für Entwickler (ca. 250 Wörter)
- **Anforderungen und Umsetzung**
  - Mitteilung der Sicherheitstests an die US-Regierung.
  - Entwicklung von Standards, Werkzeugen und Tests.
  - Herausforderungen für Entwickler.
  - Diskussion über die Umsetzbarkeit.
  - Quellen: Analysen zur US Executive Order.

### 3.3 Weitere Ziele und Maßnahmen (ca. 300 Wörter)
- **Breiterer Kontext und Implikationen**
  - Schutz der Privatsphäre und Bürgerrechte.
  - Unterstützung von Forschung und kleinen Unternehmen.
  - Richtlinien für den Einsatz von KI im Militär und Geheimdiensten.
  - Langfristige Auswirkungen und strategische Ziele.
  - Quellen: Analysen zur US Executive Order.

## 4. Vergleich EU AI Act und Executive Order
### 4.1 Unterschiede in der Risikobewertung (ca. 250 Wörter)
- **Ansätze und Methoden**
  - EU AI Act: Einteilung in Risikokategorien.
  - Executive Order: Keine Einteilung in Risikostufen.
  - Vorteile und Nachteile der unterschiedlichen Ansätze.
  - Praktische Auswirkungen auf die Implementierung.
  - Quellen: EU AI Act Dokumentation, Analysen zur US Executive Order.

### 4.2 Unterschiede in der Konkretheit der Regelungen (ca. 250 Wörter)
- **Detaillierungsgrad und Klarheit**
  - EU AI Act: Konkrete Regeln und Verbote.
  - Executive Order: Aufruf zur Definition von Regeln durch Behörden.
  - Vergleich der Detaillierung und Umsetzbarkeit.
  - Implikationen für Unternehmen und Entwickler.
  - Quellen: EU AI Act Dokumentation, Analysen zur US Executive Order.

### 4.3 Gemeinsame Ziele und unterschiedliche Schwerpunkte (ca. 250 Wörter)
- **Ziele und strategische Prioritäten**
  - Beide versuchen eine „gute AI Gesellschaft“ zu definieren.
  - EU: Schutz der Bürger im Fokus.
  - USA: Wettbewerb im Fokus.
  - Synergien und Konfliktpotenziale zwischen den Ansätzen.
  - Quellen: EU AI Act Dokumentation, Analysen zur US Executive Order.

## 5. Kritik am EU AI Act
### 5.1 Ausnehmen von militärischen Systemen
#### 5.1.1 Problematik und Begründung (ca. 250 Wörter)
- **Ethische und sicherheitstechnische Bedenken**
  - Militärische Systeme sind vom EU AI Act ausgenommen.
  - Diskussion über ethische Implikationen und Sicherheitsrisiken.
  - Auswirkungen auf das Vertrauen in den EU AI Act.
  - Bewertung der Notwendigkeit dieser Ausnahmen.
  - Quellen: Fachliteratur zur KI-Ethik, Analysen zur US Executive Order.

### 5.2 Alignment Problem
#### 5.2.1 Herausforderung und Lösungsansätze (ca. 250 Wörter)
- **Menschliche Werte und KI-Kontrolle**
  - Sicherstellung, dass KI-Systeme im Einklang mit menschlichen Werten handeln.
  - Notwendigkeit von robusten Kontrollmechanismen und Überwachung.
  - Praktische Beispiele und Lösungsansätze.
  - Diskussion über die Effektivität und Realisierbarkeit.
  - Quellen: Fachliteratur zur KI-Ethik, Analysen zur US Executive Order.

## 6. Fazit
### 6.1 Zusammenfassung der Hauptpunkte (ca. 200 Wörter)
- **Kernaspekte und Erkenntnisse**
  - EU AI Act als umfassender Rechtsrahmen für KI.
  - Balance zwischen Innovation und ethischen/moralischen Grundsätzen.
  - Vergleich zu internationalen Ansätzen wie der US Executive Order.
  - Auswirkungen auf die KI-Entwicklung und -Implementierung.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

### 6.2 Ausblick und zukünftige Entwicklungen (ca. 200 Wörter)
- **Potenzial und Herausforderungen**
  - Potenzial für Anpassungen und Verbesserungen.
  - Bedeutung internationaler Kooperation und Harmonisierung der Regelungen.
  - Langfristige Ziele und mögliche Entwicklungen.
  - Prognosen zur Zukunft der KI-Regulierung.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

## Quellen und weiterführende Literatur
- **EU AI Act Dokumentation**
  - Offizielle Veröffentlichungen und Entwürfe der EU-Kommission: [EU AI Act Documentation](https://ec.europa.eu/digital-strategy/our-policies/eu-artificial-intelligence-act_de)

- **Fachliteratur zur KI-Ethik**
  - "Artificial Intelligence: A Guide for Thinking Humans" von Melanie Mitchell
  - "Human Compatible: Artificial Intelligence and the Problem of Control" von Stuart Russell

- **Analysen zur US Executive Order**
  - Berichte von Brookings Institution: [Brookings AI Regulation](https://www.brookings.edu/research/how-the-us-can-promote-responsible-ai/)
  - Center for Data Innovation: [Data Innovation AI Regulation](https://datainnovation.org/2023/11/analyzing-bidens-ai-executive-order/)

- **Fachzeitschriften und wissenschaftliche Publikationen**
  - Journal of Artificial Intelligence Research (JAIR): [JAIR](https://www.jair.org/index.php/jair)
  - AI & Society Journal: [AI & Society](https://www.springer.com/journal/146)
