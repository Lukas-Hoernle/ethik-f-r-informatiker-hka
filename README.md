# Ausarbeitung zum EU AI Act

## Inhaltsverzeichnis
# 1. Einleitung

Der EU AI Act wurde erstmals 2021 als Entwurf vorgestellt und 2024 in seiner endgültigen Form verabschiedet. Ziel dieses Gesetzesrahmens ist es, eine einheitliche und sichere Grundlage für die Entwicklung und Anwendung künstlicher Intelligenz (KI) in der Europäischen Union zu schaffen. Der EU AI Act stellt sicher, dass KI-Systeme sicher, transparent und ethisch vertretbar eingesetzt werden. Diese Einführung gibt einen Überblick über die Notwendigkeit und die Ziele des EU AI Acts.

## Einführung in den EU AI Act (ca. 200 Wörter)

Der erste Entwurf des EU AI Acts wurde 2021 vorgestellt, und die endgültige Version trat 2024 in Kraft. Dieser Rechtsrahmen zielt darauf ab, einheitliche Standards für die Entwicklung und Nutzung von KI in der EU zu etablieren. Der EU AI Act soll sicherstellen, dass KI-Systeme vertrauenswürdig und menschenzentriert sind und dabei Innovationen fördern sowie grenzüberschreitende Anwendungen ermöglichen. 

Ein wesentlicher Aspekt des EU AI Acts ist die Schaffung eines gemeinsamen Marktes für KI in Europa. Durch die Harmonisierung der Regeln können Unternehmen ihre KI-Produkte und -Dienstleistungen leichter in verschiedenen Mitgliedstaaten anbieten, was die Wettbewerbsfähigkeit der EU auf dem globalen KI-Markt stärkt. Gleichzeitig sollen durch den EU AI Act Risiken minimiert und Grundrechte geschützt werden, insbesondere in Bezug auf Datenschutz, Sicherheit und die Vermeidung von Diskriminierung  .

## Notwendigkeit des EU AI Acts (ca. 200 Wörter)

Die Notwendigkeit des EU AI Acts ergibt sich aus der zunehmenden Verbreitung und Bedeutung von KI-Technologien in verschiedenen Bereichen des täglichen Lebens und der Wirtschaft. Ohne eine klare gesetzliche Regelung könnten KI-Systeme erhebliche Risiken für die Grundrechte der Bürger darstellen, insbesondere in Bezug auf Datenschutz und Sicherheit. Zudem könnten unregulierte KI-Anwendungen zu Diskriminierung und sozialer Ungerechtigkeit führen.

Ein weiteres Problem ist das Fehlen einheitlicher Regeln innerhalb der EU, was zu einem fragmentierten Rechtsrahmen und damit zu Unsicherheiten für Unternehmen führen könnte. Der EU AI Act zielt darauf ab, diese Lücken zu schließen und einen kohärenten, unionsweiten Rechtsrahmen zu schaffen. Dies ist besonders wichtig, da KI-Systeme zunehmend in sicherheitskritischen Bereichen wie dem Gesundheitswesen, der Strafverfolgung und der öffentlichen Verwaltung eingesetzt werden. Durch klare Vorgaben und Standards sollen diese Systeme sicher und vertrauenswürdig gestaltet werden .

## Ziele des EU AI Acts (ca. 200 Wörter)

Der EU AI Act verfolgt mehrere zentrale Ziele. Erstens soll er die Entwicklung und Nutzung von KI-Systemen fördern, die sicher, transparent und ethisch vertretbar sind. Dies bedeutet, dass KI-Anwendungen den Schutz der Gesundheit und Sicherheit der Nutzer gewährleisten und negative Auswirkungen auf die Gesellschaft minimieren müssen. Zweitens soll der EU AI Act dazu beitragen, dass die Grundrechte der Bürger gewahrt bleiben, insbesondere in Bezug auf Datenschutz und Nichtdiskriminierung.

Ein weiteres Ziel ist die Förderung von Innovation und Wettbewerbsfähigkeit der EU im globalen KI-Markt. Durch die Schaffung eines einheitlichen Rechtsrahmens werden Unternehmen ermutigt, in die Entwicklung und den Einsatz von KI zu investieren, was wiederum zu wirtschaftlichem Wachstum und technologischer Fortschritt führt. Schließlich soll der EU AI Act die Forschung und Entwicklung im Bereich der KI unterstützen, indem er klare Richtlinien und Standards setzt, die als Grundlage für die Schaffung neuer Technologien dienen .
2. Aufbau des EU AI Act
   - 2.1 Aufteilung in Risikokategorien
     - 2.1.1 Unannehmbare Risiken
     - 2.1.2 Hohe Risiken
     - 2.1.3 Begrenzte Risiken
     - 2.1.4 Geringe Risiken
     - 2.1.5 Allzweck KIs (General Purpose AI)
   - 2.2 Durchsetzen der Regelungen
     - 2.2.1 Bildung von Ausschüssen und Aufsichtsbehörden
     - 2.2.2 Einführung einer Datenbank für Hochrisiko-KI Systeme
3. Bidens Executive Order
   - 3.1 Einführung und Ziele der Executive Order
   - 3.2 Verpflichtungen für Entwickler
   - 3.3 Weitere Ziele und Maßnahmen
4. Vergleich EU AI Act und Executive Order
   - 4.1 Unterschiede in der Risikobewertung
   - 4.2 Unterschiede in der Konkretheit der Regelungen
   - 4.3 Gemeinsame Ziele und unterschiedliche Schwerpunkte
5. Kritik am EU AI Act
   - 5.1 Ausnehmen von militärischen Systemen
     - 5.1.1 Problematik und Begründung
   - 5.2 Alignment Problem
     - 5.2.1 Herausforderung und Lösungsansätze
6. Fazit
   - 6.1 Zusammenfassung der Hauptpunkte
   - 6.2 Ausblick und zukünftige Entwicklungen

## 1. Einleitung
- **Einführung in den EU AI Act** (ca. 200 Wörter)
  - Erster Entwurf 2021, endgültige Version 2024.
  - Ziel: Rechtsrahmen für vertrauenswürdige KI schaffen.
  - Schaffung eines einheitlichen Marktes für KI in Europa.
  - Förderung von Innovationen und grenzüberschreitender Nutzung von KI.
  - Quellen: Offizielle Veröffentlichungen der EU-Kommission.

- **Notwendigkeit des EU AI Acts** (ca. 200 Wörter)
  - Steigende Risiken für Grundrechte.
  - Fehlende Ressourcen und Erlaubnisse für Überwachung.
  - Gefahr eines uneinheitlichen Rechtsrahmens innerhalb der EU.
  - Zunehmende Integration von KI in verschiedenen Sektoren.
  - Quellen: Fachliteratur zur KI-Ethik.

- **Ziele des EU AI Acts** (ca. 200 Wörter)
  - Förderung von vertrauenswürdiger und menschenzentrierter KI.
  - Schutz von Gesundheit und Sicherheit.
  - Unterbindung schädlicher Auswirkungen von KI-Systemen.
  - Unterstützung von Forschung und Entwicklung in der KI.
  - Quellen: Offizielle Veröffentlichungen der EU-Kommission.

## 2. Aufbau des EU AI Act
### 2.1 Aufteilung in Risikokategorien
#### 2.1.1 Unannehmbare Risiken (ca. 300 Wörter)
- **Verbotene Anwendungen und Ausnahmen**
  - Verbotene Anwendungen wie Verhaltensbeeinflussung und Social Scoring.
  - Risiken und ethische Bedenken bei biometrischer Identifizierung.
  - Strenge Bedingungen für Ausnahmen.
  - Auswirkungen auf die gesellschaftliche Akzeptanz.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.1.2 Hohe Risiken (ca. 300 Wörter)
- **Anwendungsbereiche und Anforderungen**
  - KIs in Schutzsystemen, Spielzeug, Medizinprodukten und kritischer Infrastruktur.
  - Anforderungen an Risiko-Management, Datenüberprüfung und technische Dokumentation.
  - Beispielhafte Fälle und deren Regulierungen.
  - Evaluierung der Wirksamkeit der Maßnahmen.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.1.3 Begrenzte Risiken (ca. 250 Wörter)
- **Transparenzpflicht und Manipulation**
  - Erhöhtes Risiko für Manipulation, z.B. bei Chatbots und Deepfakes.
  - Transparenzpflicht bei KI-generierten Inhalten.
  - Schutzmaßnahmen und deren Implementierung.
  - Diskussion über die Effektivität dieser Maßnahmen.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.1.4 Geringe Risiken (ca. 250 Wörter)
- **Anwendungsbeispiele und Freiheiten**
  - KIs wie Spamfilter oder Videospiele.
  - Keine speziellen Regeln durch den EU AI Act.
  - Vorteile und mögliche Gefahren.
  - Einfluss auf die Innovationsfreiheit.
  - Quellen: EU AI Act Dokumentation.

#### 2.1.5 Allzweck KIs (General Purpose AI) (ca. 250 Wörter)
- **Charakteristika und Anforderungen**
  - Breites Allgemeinwissen, vielfältige Einsatzmöglichkeiten.
  - Technische Dokumentation und Informationsbereitstellung erforderlich.
  - Beispiele und deren Relevanz.
  - Herausforderungen bei der Regulierung.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

### 2.2 Durchsetzen der Regelungen
#### 2.2.1 Bildung von Ausschüssen und Aufsichtsbehörden (ca. 300 Wörter)
- **Strukturen und Aufgaben**
  - Europäischer Ausschuss für KI und nationale Aufsichtsbehörden.
  - Zugriff auf Dokumentationen und Daten der KI-Anbieter.
  - Korrekturmaßnahmen und Strafen bei Nichteinhaltung.
  - Effizienz und Kritik an den Strukturen.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

#### 2.2.2 Einführung einer Datenbank für Hochrisiko-KI Systeme (ca. 250 Wörter)
- **Zweck und Nutzung**
  - Registrierung vor Inbetriebnahme erforderlich.
  - Überblick über betriebene Hochrisiko-KI Systeme.
  - Transparenz und Nachvollziehbarkeit.
  - Bewertung der Praktikabilität.
  - Quellen: EU AI Act Dokumentation.

## 3. Bidens Executive Order
### 3.1 Einführung und Ziele der Executive Order (ca. 300 Wörter)
- **Hintergrund und Intention**
  - Erlassen am 30. Oktober 2023.
  - Standards für sichere, privatsphäreschützende und gleichbehandelnde KI-Systeme.
  - Förderung eines ethischen Rahmens für KI.
  - Vergleich zu früheren US-Initiativen.
  - Quellen: Analysen zur US Executive Order.

### 3.2 Verpflichtungen für Entwickler (ca. 250 Wörter)
- **Anforderungen und Umsetzung**
  - Mitteilung der Sicherheitstests an die US-Regierung.
  - Entwicklung von Standards, Werkzeugen und Tests.
  - Herausforderungen für Entwickler.
  - Diskussion über die Umsetzbarkeit.
  - Quellen: Analysen zur US Executive Order.

### 3.3 Weitere Ziele und Maßnahmen (ca. 300 Wörter)
- **Breiterer Kontext und Implikationen**
  - Schutz der Privatsphäre und Bürgerrechte.
  - Unterstützung von Forschung und kleinen Unternehmen.
  - Richtlinien für den Einsatz von KI im Militär und Geheimdiensten.
  - Langfristige Auswirkungen und strategische Ziele.
  - Quellen: Analysen zur US Executive Order.

## 4. Vergleich EU AI Act und Executive Order
### 4.1 Unterschiede in der Risikobewertung (ca. 250 Wörter)
- **Ansätze und Methoden**
  - EU AI Act: Einteilung in Risikokategorien.
  - Executive Order: Keine Einteilung in Risikostufen.
  - Vorteile und Nachteile der unterschiedlichen Ansätze.
  - Praktische Auswirkungen auf die Implementierung.
  - Quellen: EU AI Act Dokumentation, Analysen zur US Executive Order.

### 4.2 Unterschiede in der Konkretheit der Regelungen (ca. 250 Wörter)
- **Detaillierungsgrad und Klarheit**
  - EU AI Act: Konkrete Regeln und Verbote.
  - Executive Order: Aufruf zur Definition von Regeln durch Behörden.
  - Vergleich der Detaillierung und Umsetzbarkeit.
  - Implikationen für Unternehmen und Entwickler.
  - Quellen: EU AI Act Dokumentation, Analysen zur US Executive Order.

### 4.3 Gemeinsame Ziele und unterschiedliche Schwerpunkte (ca. 250 Wörter)
- **Ziele und strategische Prioritäten**
  - Beide versuchen eine „gute AI Gesellschaft“ zu definieren.
  - EU: Schutz der Bürger im Fokus.
  - USA: Wettbewerb im Fokus.
  - Synergien und Konfliktpotenziale zwischen den Ansätzen.
  - Quellen: EU AI Act Dokumentation, Analysen zur US Executive Order.

## 5. Kritik am EU AI Act
### 5.1 Ausnehmen von militärischen Systemen
#### 5.1.1 Problematik und Begründung (ca. 250 Wörter)
- **Ethische und sicherheitstechnische Bedenken**
  - Militärische Systeme sind vom EU AI Act ausgenommen.
  - Diskussion über ethische Implikationen und Sicherheitsrisiken.
  - Auswirkungen auf das Vertrauen in den EU AI Act.
  - Bewertung der Notwendigkeit dieser Ausnahmen.
  - Quellen: Fachliteratur zur KI-Ethik, Analysen zur US Executive Order.

### 5.2 Alignment Problem
#### 5.2.1 Herausforderung und Lösungsansätze (ca. 250 Wörter)
- **Menschliche Werte und KI-Kontrolle**
  - Sicherstellung, dass KI-Systeme im Einklang mit menschlichen Werten handeln.
  - Notwendigkeit von robusten Kontrollmechanismen und Überwachung.
  - Praktische Beispiele und Lösungsansätze.
  - Diskussion über die Effektivität und Realisierbarkeit.
  - Quellen: Fachliteratur zur KI-Ethik, Analysen zur US Executive Order.

## 6. Fazit
### 6.1 Zusammenfassung der Hauptpunkte (ca. 200 Wörter)
- **Kernaspekte und Erkenntnisse**
  - EU AI Act als umfassender Rechtsrahmen für KI.
  - Balance zwischen Innovation und ethischen/moralischen Grundsätzen.
  - Vergleich zu internationalen Ansätzen wie der US Executive Order.
  - Auswirkungen auf die KI-Entwicklung und -Implementierung.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

### 6.2 Ausblick und zukünftige Entwicklungen (ca. 200 Wörter)
- **Potenzial und Herausforderungen**
  - Potenzial für Anpassungen und Verbesserungen.
  - Bedeutung internationaler Kooperation und Harmonisierung der Regelungen.
  - Langfristige Ziele und mögliche Entwicklungen.
  - Prognosen zur Zukunft der KI-Regulierung.
  - Quellen: EU AI Act Dokumentation, Fachliteratur zur KI-Ethik.

## Quellen und weiterführende Literatur
- **EU AI Act Dokumentation**
  - Offizielle Veröffentlichungen und Entwürfe der EU-Kommission: [EU AI Act Documentation](https://ec.europa.eu/digital-strategy/our-policies/eu-artificial-intelligence-act_de)

- **Fachliteratur zur KI-Ethik**
  - "Artificial Intelligence: A Guide for Thinking Humans" von Melanie Mitchell
  - "Human Compatible: Artificial Intelligence and the Problem of Control" von Stuart Russell

- **Analysen zur US Executive Order**
  - Berichte von Brookings Institution: [Brookings AI Regulation](https://www.brookings.edu/research/how-the-us-can-promote-responsible-ai/)
  - Center for Data Innovation: [Data Innovation AI Regulation](https://datainnovation.org/2023/11/analyzing-bidens-ai-executive-order/)

- **Fachzeitschriften und wissenschaftliche Publikationen**
  - Journal of Artificial Intelligence Research (JAIR): [JAIR](https://www.jair.org/index.php/jair)
  - AI & Society Journal: [AI & Society](https://www.springer.com/journal/146)
