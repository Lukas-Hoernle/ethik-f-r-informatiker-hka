# Ausarbeitung zum EU AI Act

## Inhaltsverzeichnis
1. Einleitung
2. Aufbau des EU AI Act
   - 2.1 Aufteilung in Risikokategorien
     - 2.1.1 Unannehmbare Risiken
     - 2.1.2 Hohe Risiken
     - 2.1.3 Begrenzte Risiken
     - 2.1.4 Geringe Risiken
     - 2.1.5 Allzweck KIs (General Purpose AI)
   - 2.2 Durchsetzen der Regelungen
     - 2.2.1 Bildung von Ausschüssen und Aufsichtsbehörden
     - 2.2.2 Einführung einer Datenbank für Hochrisiko-KI Systeme
3. Bidens Executive Order
   - 3.1 Einführung und Ziele der Executive Order
   - 3.2 Verpflichtungen für Entwickler
   - 3.3 Weitere Ziele und Maßnahmen
4. Vergleich EU AI Act und Executive Order
   - 4.1 Unterschiede in der Risikobewertung
   - 4.2 Unterschiede in der Konkretheit der Regelungen
   - 4.3 Gemeinsame Ziele und unterschiedliche Schwerpunkte
5. Kritik am EU AI Act
   - 5.1 Ausnehmen von militärischen Systemen
     - 5.1.1 Problematik und Begründung
   - 5.2 Alignment Problem
     - 5.2.1 Herausforderung und Lösungsansätze
6. Fazit
   - 6.1 Zusammenfassung der Hauptpunkte
   - 6.2 Ausblick und zukünftige Entwicklungen

## 1. Einleitung
- **Einführung in den EU AI Act** (4-5 Sätze)
  - Erster Entwurf 2021, endgültige Version 2024.
  - Ziel: Rechtsrahmen für vertrauenswürdige KI schaffen.
  - Schaffung eines einheitlichen Marktes für KI in Europa.
  - Förderung von Innovationen und grenzüberschreitender Nutzung von KI.
- **Notwendigkeit des EU AI Acts** (4-5 Sätze)
  - Steigende Risiken für Grundrechte.
  - Fehlende Ressourcen und Erlaubnisse für Überwachung.
  - Gefahr eines uneinheitlichen Rechtsrahmens innerhalb der EU.
  - Zunehmende Integration von KI in verschiedenen Sektoren.
- **Ziele des EU AI Acts** (4-5 Sätze)
  - Förderung von vertrauenswürdiger und menschenzentrierter KI.
  - Schutz von Gesundheit und Sicherheit.
  - Unterbindung schädlicher Auswirkungen von KI-Systemen.
  - Unterstützung von Forschung und Entwicklung in der KI.

## 2. Aufbau des EU AI Act
### 2.1 Aufteilung in Risikokategorien
#### 2.1.1 Unannehmbare Risiken
- **Verbotene Anwendungen und Ausnahmen** (5-6 Sätze)
  - Verbotene Anwendungen wie Verhaltensbeeinflussung und Social Scoring.
  - Risiken und ethische Bedenken bei biometrischer Identifizierung.
  - Strenge Bedingungen für Ausnahmen.
  - Auswirkungen auf die gesellschaftliche Akzeptanz.
#### 2.1.2 Hohe Risiken
- **Anwendungsbereiche und Anforderungen** (5-6 Sätze)
  - KIs in Schutzsystemen, Spielzeug, Medizinprodukten und kritischer Infrastruktur.
  - Anforderungen an Risiko-Management, Datenüberprüfung und technische Dokumentation.
  - Beispielhafte Fälle und deren Regulierungen.
  - Evaluierung der Wirksamkeit der Maßnahmen.
#### 2.1.3 Begrenzte Risiken
- **Transparenzpflicht und Manipulation** (4-5 Sätze)
  - Erhöhtes Risiko für Manipulation, z.B. bei Chatbots und Deepfakes.
  - Transparenzpflicht bei KI-generierten Inhalten.
  - Schutzmaßnahmen und deren Implementierung.
  - Diskussion über die Effektivität dieser Maßnahmen.
#### 2.1.4 Geringe Risiken
- **Anwendungsbeispiele und Freiheiten** (4-5 Sätze)
  - KIs wie Spamfilter oder Videospiele.
  - Keine speziellen Regeln durch den EU AI Act.
  - Vorteile und mögliche Gefahren.
  - Einfluss auf die Innovationsfreiheit.
#### 2.1.5 Allzweck KIs (General Purpose AI)
- **Charakteristika und Anforderungen** (4-5 Sätze)
  - Breites Allgemeinwissen, vielfältige Einsatzmöglichkeiten.
  - Technische Dokumentation und Informationsbereitstellung erforderlich.
  - Beispiele und deren Relevanz.
  - Herausforderungen bei der Regulierung.

### 2.2 Durchsetzen der Regelungen
#### 2.2.1 Bildung von Ausschüssen und Aufsichtsbehörden
- **Strukturen und Aufgaben** (5-6 Sätze)
  - Europäischer Ausschuss für KI und nationale Aufsichtsbehörden.
  - Zugriff auf Dokumentationen und Daten der KI-Anbieter.
  - Korrekturmaßnahmen und Strafen bei Nichteinhaltung.
  - Effizienz und Kritik an den Strukturen.
#### 2.2.2 Einführung einer Datenbank für Hochrisiko-KI Systeme
- **Zweck und Nutzung** (4-5 Sätze)
  - Registrierung vor Inbetriebnahme erforderlich.
  - Überblick über betriebene Hochrisiko-KI Systeme.
  - Transparenz und Nachvollziehbarkeit.
  - Bewertung der Praktikabilität.

## 3. Bidens Executive Order
### 3.1 Einführung und Ziele der Executive Order
- **Hintergrund und Intention** (5-6 Sätze)
  - Erlassen am 30. Oktober 2023.
  - Standards für sichere, privatsphäreschützende und gleichbehandelnde KI-Systeme.
  - Förderung eines ethischen Rahmens für KI.
  - Vergleich zu früheren US-Initiativen.
### 3.2 Verpflichtungen für Entwickler
- **Anforderungen und Umsetzung** (4-5 Sätze)
  - Mitteilung der Sicherheitstests an die US-Regierung.
  - Entwicklung von Standards, Werkzeugen und Tests.
  - Herausforderungen für Entwickler.
  - Diskussion über die Umsetzbarkeit.
### 3.3 Weitere Ziele und Maßnahmen
- **Breiterer Kontext und Implikationen** (5-6 Sätze)
  - Schutz der Privatsphäre und Bürgerrechte.
  - Unterstützung von Forschung und kleinen Unternehmen.
  - Richtlinien für den Einsatz von KI im Militär und Geheimdiensten.
  - Langfristige Auswirkungen und strategische Ziele.

## 4. Vergleich EU AI Act und Executive Order
### 4.1 Unterschiede in der Risikobewertung
- **Ansätze und Methoden** (4-5 Sätze)
  - EU AI Act: Einteilung in Risikokategorien.
  - Executive Order: Keine Einteilung in Risikostufen.
  - Vorteile und Nachteile der unterschiedlichen Ansätze.
  - Praktische Auswirkungen auf die Implementierung.
### 4.2 Unterschiede in der Konkretheit der Regelungen
- **Detaillierungsgrad und Klarheit** (4-5 Sätze)
  - EU AI Act: Konkrete Regeln und Verbote.
  - Executive Order: Aufruf zur Definition von Regeln durch Behörden.
  - Vergleich der Detaillierung und Umsetzbarkeit.
  - Implikationen für Unternehmen und Entwickler.
### 4.3 Gemeinsame Ziele und unterschiedliche Schwerpunkte
- **Ziele und strategische Prioritäten** (4-5 Sätze)
  - Beide versuchen eine „gute AI Gesellschaft“ zu definieren.
  - EU: Schutz der Bürger im Fokus.
  - USA: Wettbewerb im Fokus.
  - Synergien und Konfliktpotenziale zwischen den Ansätzen.

## 5. Kritik am EU AI Act
### 5.1 Ausnehmen von militärischen Systemen
#### 5.1.1 Problematik und Begründung
- **Ethische und sicherheitstechnische Bedenken** (4-5 Sätze)
  - Militärische Systeme sind vom EU AI Act ausgenommen.
  - Diskussion über ethische Implikationen und Sicherheitsrisiken.
  - Auswirkungen auf das Vertrauen in den EU AI Act.
  - Bewertung der Notwendigkeit dieser Ausnahmen.
### 5.2 Alignment Problem
#### 5.2.1 Herausforderung und Lösungsansätze
- **Menschliche Werte und KI-Kontrolle** (4-5 Sätze)
  - Sicherstellung, dass KI-Systeme im Einklang mit menschlichen Werten handeln.
  - Notwendigkeit von robusten Kontrollmechanismen und Überwachung.
  - Praktische Beispiele und Lösungsansätze.
  - Diskussion über die Effektivität und Realisierbarkeit.

## 6. Fazit
### 6.1 Zusammenfassung der Hauptpunkte
- **Kernaspekte und Erkenntnisse** (4-5 Sätze)
  - EU AI Act als umfassender Rechtsrahmen für KI.
  - Balance zwischen Innovation und ethischen/moralischen Grundsätzen.
  - Vergleich zu internationalen Ansätzen wie der US Executive Order.
  - Auswirkungen auf die KI-Entwicklung und -Implementierung.
### 6.2 Ausblick und zukünftige Entwicklungen
- **Potenzial und Herausforderungen** (4-5 Sätze)
  - Potenzial für Anpassungen und Verbesserungen.
  - Bedeutung internationaler Kooperation und Harmonisierung der Regelungen.
  - Langfristige Ziele und mögliche Entwicklungen.
  - Prognosen zur Zukunft der KI-Regulierung.

## Quellen und weiterführende Literatur
- **EU AI Act Dokumentation**
  - Offizielle Veröffentlichungen und Entwürfe der EU-Kommission.
- **Fachliteratur zur KI-Ethik**
  - Bücher und Artikel über ethische Implikationen von KI.
- **Analysen zur US Executive Order**
  - Berichte und Analysen von Experten zu den US-Regulierungen.
- **Fachzeitschriften und wissenschaftliche Publikationen**
  - Artikel in Fachzeitschriften zu KI-Regulierung und -Entwicklung.
